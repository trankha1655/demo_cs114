# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'untitled.ui'
#
# Created by: PyQt5 UI code generator 5.15.4
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtWidgets import (QWidget, QDialog, QLabel,
                    QGridLayout, QVBoxLayout, QSizePolicy, QApplication)

from PyQt5.QtGui import QImage, QPixmap, QFont, QIcon
from PyQt5.QtCore import (QThread, pyqtSignal, pyqtSlot, QSize,
                    Qt, QTime, QTimer, QObject, QEvent)

import qdarkstyle

from collections import OrderedDict,deque
import numpy as np
from typing import Any, Dict, List
import cv2
import os

import albumentations as A
import torch
import torch.nn as nn

from Source.Model.SS.enet_model import enet_get_model
#import torch.multiprocessing.spawn as spawn

from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as pp_mb
from tensorflow.keras.models import load_model,Model

from threading import Thread
from matplotlib import pyplot as plt
import time

os.environ['OPENCV_VIDEOIO_DEBUG'] ='1'
os.environ['OPENCV_VIDEOIO_PRIORITY_MSMF'] = '0'

width, height =640, 360
w = 1188
h = 729

capture_delay =80

            


def exit_application():
    """Exit program event handler"""
    
    sys.exit(1)


class NewWindow(QDialog):
    def __init__(self, parent: QWidget) -> None:
        QDialog.__init__(self, parent)
        self.parent = parent
        self.index: int = 0 

        self.label =QLabel()
        self.label.setSizePolicy(QSizePolicy.Ignored,QSizePolicy.Ignored)
        self.label.setScaledContents(True)
        self.label.setFont(QFont("Times",30))
        self.label.setStyleSheet(
                "color: rgb(255,0,255);" 
                "background-color: rgb(0,0,0);"
                "qproperty-alignment: AlignCenter;")

        layout = QVBoxLayout()
        layout.setContentsMargins(0,0,0,0)
        layout.addWidget(self.label)
        self.setLayout(layout)
        self.setWindowTitle("Camera {}".format(self.index))


    def resizeHint(self) ->QSize:
            return QSize(w//2, h//2)

    def resizeEvent(self, event)-> None:
        self.update()
    
    def keyPressEvent(self, event)-> None:
        if event.key() == Qt.Key_Escape:
            self.accept()

    



class Window(QWidget):
    def __init__(self, cams: Dict[int,str]) ->None:
        super(Window, self).__init__()
        self.cameras: Dict[int, List[Any]]= OrderedDict()
        index: int

        self.cap = []

        self.fps=0
        
        model1= enet_get_model("ckpt-enet_midcam_0.46.pth","cuda:0")
        model2 = enet_get_model("ckpt-enet_2cam_0.67.pth","cuda:0")

        self.pred_model= load_model("Model_MobileNet_0.77.h5",compile=False)
        "Inference Model is loaded..."



        self.model = [model2,model1]

        #print(cams)
        for index in range(len(cams.keys())):
            self.cameras[index] = [None, None, False]
            
        index =0

        for cam_id, link in cams.items():
            self.cameras[index] = [cam_id, link, False]
            index +=1

        self.deque_frame = [deque(maxlen=1),deque(maxlen=1),deque(maxlen=1)]
        self.deque_plot = deque(maxlen=1)

        self.check_pre = np.array([0,0,0])
        self.ts_pre = np.zeros((1,3,224,224,3))

        self.pred_model.predict(self.ts_pre)

        self.online =False


        #init frame
        self.deque_plot.append((0,self.ts_pre))
        self.deque_plot.append((1,self.ts_pre))
        self.deque_plot.append((2,self.ts_pre))

        #print("cameras",self.cameras)
        # main layout

        layout = QGridLayout()
        layout.setContentsMargins(0,0,0,0)
        layout.setSpacing(2)

        #self.deque = deque(maxlen=lenQueue)
        self.initCam()

        self.labels: List[QLabel] = []
        #self.threads: List[Slot] = []
        

        
        Thread(target=self.get_frame, args=()).start()
        
        """ self.get_frame_thread.daemon = True
        self.get_frame_thread.start()"""

        for index, value in self.cameras.items():
            cam_id, link, active = value

            # threads


            label = QLabel()
            label.setSizePolicy(QSizePolicy.Ignored, QSizePolicy.Ignored)
            label.setScaledContents(True)
            label.setFont(QFont("Times",30))
            label.setStyleSheet(
                "color: rgb(255,0,255); background-color: rgb(0,0,0);"
                "qproperty-alignment: AlignCenter;")

            

            #clickable(label).connect(partial(self.showCam,index))
            self.labels.append(label)

            if index ==0:
                layout.addWidget(label,0,0)
                print(1)
            elif index ==1:
                layout.addWidget(label,0,1)
                print(2)
            elif index ==2:
                layout.addWidget(label,1,0)
                print(3)
            elif index ==3:
                layout.addWidget(label,1,1)
                print(4)
            else:
                raise ValueError("n  Camera != rows/cols")

        Inference_label =QLabel()
        Inference_label.setSizePolicy(QSizePolicy.Ignored, QSizePolicy.Ignored)
        Inference_label.setScaledContents(True)
        Inference_label.setFont(QFont("Times",30))
        Inference_label.setStyleSheet(
                "color: rgb(255,0,255); background-color: rgb(0,0,0);"
                "qproperty-alignment: AlignCenter;")

        self.labels.append(Inference_label)
        layout.addWidget(Inference_label,1,1)
        self.categ= np.array([0.95456,0.94564,0.94564])

        self.im_label= (np.ones((320,640,3))*225).astype("int8")
        cv2.rectangle(self.im_label, (170,75), (530,200), color=(5,5,5), thickness=-1)


        
        

        self.timer = QTimer()
        self.timer.timeout.connect(self.set_frame)
        print("start load Window!")
        self.timer.start(0.02)

        Thread(target=self.semantic_frame, args=() ).start()

        self.setLayout(layout)
        self.setWindowTitle("Tracking_Predict")
        #self.setWindowIcon(QIcon("icon.png"))

        Thread(target=self.pred_frame).start()
        self.newWindow = NewWindow(self)

        #self.refresh()

    def initCam(self):
        print("init camera...")
        for index, value in self.cameras.items():
            cam_id, link, active = value
            print(link)
            self.cap.append(cv2.VideoCapture(link))
        print("len cap:", len(self.cap))

    def get_frame(self):
        print("Reads frame, resizes, and prepare to segment...")
        device="cuda:0"
        #cap = self.cap[index]
        seg_resize  = A.Compose([
            A.Resize(width=640, height=320),
        ])

       

        while True:
            for index in range(3):
                try:
                    if self.cap[index].isOpened():
                        # Read next frame from stream and insert into deque
                        #print("captured!",index)
                        status, frame = self.cap[index].read()
                        if status:
                            
                            frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)
                            

                            frame = seg_resize(image=frame)["image"]

                            tmg = torch.tensor(frame).unsqueeze(0).float()
                            tmg = tmg.transpose(2, 3).transpose(1, 2).to(device).float()

                            self.online =True
                            self.deque_frame[index].append((frame,tmg))
                            self.spin(0.01)
                        else:
                            cap[index].release()
                            
                        # Attempt to reconnect
                        

                    self.spin(.009)
                except AttributeError:
                    pass
            self.online=False
            #print("camera is ended!...")
            

    def semantic_frame(self):

        print("segment and crop, prepare to predict class...")

        device="cuda:0"

        resize_mb = A.Compose([
            A.Resize(width=224, height=224)
        ])
        zero1 = np.zeros(3)
        zero5 = np.zeros((1,3,224,224,3))

        def apply_mask(img,mask):

            if mask.shape[-1] !=3:
                enc= np.array([[0,0,0],[255,255,255]])
                viamask =enc[mask]

            

            af_crop = np.where(viamask==np.array([0,0,0]),viamask,img)
            af_crop =resize_mb(image=af_crop.astype("float32"))["image"]

            red= np.array([255,0,0]).astype(np.float32)
            blend = 0.45*red+ 0.55*img.astype(np.float32)
    

            return af_crop, np.where(viamask==np.array([0,0,0]),img,blend).astype("int8")
        
        ct= time.time()
        while True:
            
            while self.online:
                
                for index in range(3):
                    ss= time.time()
                    pack = self.deque_frame[index][-1]
                    img ,tmg = pack[0], pack[1]


                    with torch.no_grad():
                        #nw= time.time()
                        out1 = self.model[index%2](tmg).squeeze(0)
                        mask = out1.data.max(0)[1].cpu().numpy()
                        #print(cam,time.time()-nw)

                        if mask.sum() <10000:
                            self.deque_plot.append((index,img))
                        else:
                            # segment
                            im_pre,imgplot= apply_mask(img,mask)
                            
                            self.deque_plot.append((index,imgplot))
                            
                            # tensor predcit 
                            
                            self.ts_pre[0,index,]= im_pre
                            self.check_pre[index] =1
                             

                    self.fps = 1.0/ (time.time()-ss)
                #print("No data to segment...!")"""
        

    def pred_frame(self):

        zero1 = np.zeros(3)
        zero5 = np.zeros((1,3,224,224,3))

        while True:
            if sum(self.check_pre) ==3:
                ts = self.ts_pre.copy()
                self.categ= self.pred_model.predict(pp_mb(ts))[0]
                self.ts_pre = zero5
                self.check_pre = zero1
                print(self.categ)
    

    def set_frame(self) -> None:

        
        index, im= self.deque_plot[-1]
        
        #print(index)
        cv2.rectangle(im, (640-190,0), (640,50), color=(0,0,0), thickness=-1)
        cv2.putText(im, str(self.fps)[:4],
                     (640-175,37), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), lineType=cv2.LINE_AA)


        im = QImage(im.data, im.shape[1], im.shape[0], QImage.Format_RGB888)#.rgbSwapped()
        self.labels[index].setPixmap(QPixmap.fromImage(im)) 
        

        im_label = self.im_label.copy()

        cv2.putText(im_label, str(self.categ.round(3)),
                     (195,134), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), lineType=cv2.LINE_AA)

        impre= QImage(im_label.data, im_label.shape[1], im_label.shape[0], QImage.Format_RGB888)
        self.labels[-1].setPixmap(QPixmap.fromImage(impre)) 


        if index == self.newWindow.index:
            self.newWindow.label.setPixmap(QPixmap.fromImage(im))



    def spin(self, seconds):
        """Pause for set amount of seconds, replaces time.sleep so program doesnt stall"""

        time_end = time.time() + seconds
        while time.time() < time_end:
            QtGui.QApplication.processEvents()

    def resizeHint(self) ->QSize:
        return QSize(w, h)

    def resizeEvent(self, event)-> None:
        self.update()
    
    def keyPressEvent(self, event)-> None:
        if event.key() == Qt.Key_Escape:
            for thread in self.threads:
                thread.exit()
            self.close()

    def closeEvent(self, event):
        pass

    def showCam(self, index: Any) -> None:
        self.newWindow.index = index
        if not self.cameras[index][2]:
            text_ ="Camera {}\nInactive!".format(self.cameras[index][0])
        
        self.newWindow.setWindowTitle(self.cameras[index][0])
    
    def refresh(self) -> None:
        
        for slot in self.threads:
            slot.start()


        

if __name__ == "__main__":
    import sys

    cams: Dict[int, Any] = OrderedDict()

    
    cams[1] = "demo_cam1.mp4"
    cams[2] = "demo_cam2.mp4"
    cams[3] = "demo_cam3.mp4"
    
    app = QApplication(sys.argv)

    win = Window(cams=cams)
    
  

    win.setFixedWidth(w)
    win.setFixedHeight(h)

    
    
    win.show()
    
    
    QtWidgets.QShortcut(QtGui.QKeySequence('Ctrl+Q'), win, exit_application)
   

    sys.exit(app.exec_())
 
    

